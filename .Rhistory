channel<-odbcConnect("MySQL",uid="root",pwd="77297729")
setwd("E:\\R\\MyStudy")
SZ_Stock <- read.delim("E:/R/MyStudy/SZ_Stock.txt",dec = ",")
nrow(SZ_Stock)
names(SZ_Stock) <- c("CODE","COMPANY_ABBR","COMPANY_FULL_NAME","ENGLISH_NAME","ADDR","A_CODE","A_ABBR",
"A_OFFER_DATE","A_CAPITAL","A_SHARES_CAPITAL","B_CODE","B_ABBR"
,"B_OFFER_DATE","B_CAPITAL","B_SHARES_CAPITAL","REGION","PROVINCE","CITY","INDUSTRY","WEB_SITE")
head(SZ_Stock)
sqlSave(channel, SZ_Stock,"STOCK_CODE_SZ",rownames=FALSE)
odbcClose(channel)
library(RODBC)
library(ggplot2)
channel<-odbcConnect("MySQL",uid="root",pwd="77297729")
setwd("E:\\R\\MyStudy")
SZ_Stock <- read.delim("E:/R/MyStudy/SZ_Stock.txt",dec = ",")
nrow(SZ_Stock)
names(SZ_Stock) <- c("CODE","COMPANY_ABBR","COMPANY_FULL_NAME","ENGLISH_NAME","ADDR","A_CODE","A_ABBR",
"A_OFFER_DATE","A_CAPITAL","A_SHARES_CAPITAL","B_CODE","B_ABBR"
,"B_OFFER_DATE","B_CAPITAL","B_SHARES_CAPITAL","REGION","PROVINCE","CITY","INDUSTRY","WEB_SITE")
head(SZ_Stock)
sqlSave(channel, SZ_Stock,"STOCK_CODE_BASE_INFO5",rownames=FALSE)
odbcClose(channel)
#GetAllStockCode
#本程序类用RCURL从上海证券交易所网站上抓取沪市证券股票代码
#输出1： 将所抓取的结果输入到E:\\R\\MyStudy\\Stock_info2.csv
#输入2:  MySQL DB:stock_dw.STOCK_CODE_SH
library("bitops")
library("XML")
library("RCurl")
library(rjson)
library(xts)
library(zoo)
library(quantmod)
#自定义函数,获取股票历史数据
getHistoryPrice <- function(x){
#
}
setwd("E:\\R\\MyStudy")
#从上海证交所获取信息
header02 <- c("Host"="query.sse.com.cn",
"User-Agent"="Mozilla/5.0 (Windows NT 6.1; WOW64; rv:38.0) Gecko/20100101 Firefox/38.0",
"Accept"="*/*",
"Accept-Language"="zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3",
"Accept-Encoding"="gzip, deflate",
"Referer"="http://www.sse.com.cn/assortment/stock/list/name/",
"Connection"="keep-alive"
)
url03 <- "http://query.sse.com.cn/commonQuery.do?jsonCallBack=jsonpCallback90870&isPagination=true&sqlId=COMMON_SSE_ZQPZ_GPLB_MCJS_SSAG_L&pageHelp.pageSize=5000&pageHelp.pageNo=1&pageHelp.beginPage=1&pageHelp.endPage=5&_=1433863568061"
page03 <- getURL(url03, httpHeader=header02)
temp <- substring(page03,20);
jsonData <- fromJSON(temp)
info <- data.frame(NUM=numeric(),FULLNAME=numeric(),PRODUCTNAME=numeric(),PRODUCTID=numeric())
i <- 1;
for (x in jsonData$pageHelp$data) {
#info[i] <- paste(x$NUM, x$FULLNAME, x$PRODUCTNAME, x$PRODUCTID,sep=",")
info[i,"NUM"] <- x$NUM
info[i,"FULLNAME"] <- x$FULLNAME
info[i,"PRODUCTNAME"] <- x$PRODUCTNAME
info[i,"PRODUCTID"] <- x$PRODUCTID
i <- i + 1
}
#抽取历史价格
#getHistoryPrice("600000")
#输出部分
#输出1: 使用write.csv函数将数据写成CSV文件，以供Excel打开
names(info) <- c("NUM","FULLNAME","PRODUCTNAME","PRODUCTID")
write.csv(info,"StockSH.csv")
#输出2: 将数据写入到MYSQL数据库
library(RODBC)
channel_sh<-odbcConnect("MySQL",uid="root",pwd="77297729")
sqlDrop(channel_sh,"STOCK_CODE_SH")
sqlSave(channel_sh, info,"STOCK_CODE_SH",rownames=FALSE)
odbcClose(channel_sh)
#GetAllStockCode
#本程序类用RCURL从上海证券交易所网站上抓取沪市证券股票代码
#输出1： 将所抓取的结果输入到E:\\R\\MyStudy\\Stock_info2.csv
#输入2:  MySQL DB:stock_dw.STOCK_CODE_SH
library("bitops")
library("XML")
library("RCurl")
library(rjson)
library(zoo)
library(xts)
library(quantmod)
#自定义函数,获取股票历史数据
getHistoryPrice <- function(x){
#
}
setwd("E:\\R\\MyStudy")
#从上海证交所获取信息
header02 <- c("Host"="query.sse.com.cn",
"User-Agent"="Mozilla/5.0 (Windows NT 6.1; WOW64; rv:38.0) Gecko/20100101 Firefox/38.0",
"Accept"="*/*",
"Accept-Language"="zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3",
"Accept-Encoding"="gzip, deflate",
"Referer"="http://www.sse.com.cn/assortment/stock/list/name/",
"Connection"="keep-alive"
)
url03 <- "http://query.sse.com.cn/commonQuery.do?jsonCallBack=jsonpCallback90870&isPagination=true&sqlId=COMMON_SSE_ZQPZ_GPLB_MCJS_SSAG_L&pageHelp.pageSize=5000&pageHelp.pageNo=1&pageHelp.beginPage=1&pageHelp.endPage=5&_=1433863568061"
page03 <- getURL(url03, httpHeader=header02)
temp <- substring(page03,20);
jsonData <- fromJSON(temp)
info <- data.frame(NUM=numeric(),FULLNAME=numeric(),PRODUCTNAME=numeric(),PRODUCTID=numeric())
i <- 1;
for (x in jsonData$pageHelp$data) {
#info[i] <- paste(x$NUM, x$FULLNAME, x$PRODUCTNAME, x$PRODUCTID,sep=",")
info[i,"NUM"] <- x$NUM
info[i,"FULLNAME"] <- x$FULLNAME
info[i,"PRODUCTNAME"] <- x$PRODUCTNAME
info[i,"PRODUCTID"] <- x$PRODUCTID
i <- i + 1
}
#抽取历史价格
#getHistoryPrice("600000")
#输出部分
#输出1: 使用write.csv函数将数据写成CSV文件，以供Excel打开
names(info) <- c("NUM","FULLNAME","PRODUCTNAME","PRODUCTID")
write.csv(info,"StockSH.csv")
#输出2: 将数据写入到MYSQL数据库
library(RODBC)
channel_sh<-odbcConnect("MySQL",uid="root",pwd="77297729")
sqlDrop(channel_sh,"STOCK_CODE_SH")
sqlSave(channel_sh, info,"STOCK_CODE_SH",rownames=FALSE)
odbcClose(channel_sh)
library(tseries)
library(xts)
library(zoo)
library(quantmod)
install.packages(tseries)
install.packages("tseries")
install.packages("tseries")
library(tseries)
library(xts)
library(zoo)
library(quantmod)
library(tseries)
library(zoo)
library(xts)
library(quantmod)
code <- '600036.ss'
GSPC<- as.xts(get.hist.quote(instrument=code,start='2014-01-01',
quote = c("Open", "High", "Low", "Close","Volume","AdjClose")))
help(download.file)
code <- '600036.ss'
GSPC<- as.xts(get.hist.quote(instrument=code,
quote = c("Open", "High", "Low", "Close","Volume","AdjClose")))
tail(GSPC)
head(GSPC)
mode(GSPC)
length(GSPC)
library(RODBC)
channel_sh<-odbcConnect("MySQL",uid="root",pwd="77297729")
library(RODBC)
channel_sh<-odbcConnect("MySQL",uid="root",pwd="77297729")
stockInfo <- sqlQuery("select productid from STOCK_CODE_SH")
stockInfo <- sqlQuery(channel_sh,"select productid from STOCK_CODE_SH")
stockInfo
head(stockInfo)
code <- stockInfo[1]
code
code <- stockInfo[1][1]
code
code <- stockInfo[[1]]
code
code <- stockInfo$productid
code
code <- stockInfo$productid[1]
code
code <- stockInfo$productid[1]
GSPC<- as.xts(get.hist.quote(instrument=paste(code,'ss',rep="."),
quote = c("Open", "High", "Low", "Close","Volume","AdjClose")))
paste(code,'ss',req=".")
code <- stockInfo$productid[1]
code
paste(code,'ss',sep=".")
GSPC<- as.xts(get.hist.quote(instrument=paste(code,'ss',sep="."),
quote = c("Open", "High", "Low", "Close","Volume","AdjClose")))
GSPC
tail(GSPC)
names(GSPC) <- c("Date",Open", "High", "Low", "Close","Volume","AdjClose")
names(GSPC) <- c("Date","Open", "High", "Low", "Close","Volume","AdjClose")
names(GSPC)
require(RCurl)
require(XML)
require(plyr)
require(TSA)
require(ggplot2)
verifyYears  <- function(code,year.start,year.end,myheader){
url  <-paste("http://vip.stock.finance.sina.com.cn/corp/go.php/vMS_MarketHistory/stockid/",
code,".phtml?year=2014&jidu=1",sep="")
webpage <- getURL(url,httpheader = myheader);
pagetree <- htmlTreeParse(webpage,encoding="utf-8", error=function(...){}, useInternalNodes = TRUE,trim=F)
years <- xpathSApply(pagetree,'//*/form[@name="daily"]/select[@name="year"]/option',xmlValue)
years  <- as.numeric(years)
minYear  <- min(years)
maxYear <- max(years)
if(year.start < minYear || year.end >maxYear){
stop("invalid time interval,max year is\t",maxYear,"min year is\t" ,minYear)
}
}
###主函数
#'@param code  股票代码在沪深交易所网站课直接获得
#'@param year.start 起始年
#'@param 终止年
#'@param path 保存到的文件路径，直接输入文件名则保存在工作目录下
#'@return  不凡任何值，直接将数据写入path中（直接读取会出现错误）
getAllInfo.TQ  <- function(code,year.start,year.end,myheader,path){
verifyYears(code,year.start,year.end,myheader)
years =seq(from = year.start,to = year.end,by = 1);
urls  <- paste("http://vip.stock.finance.sina.com.cn/corp/go.php/vMS_MarketHistory/stockid/",
code,".phtml?year=",years,sep="");
res <- ldply(urls,getSingleInfo.TQ,myheader,.progress =  "win")
names(res) <- c("date","open","high","close","low","volume","total_pay")
write.csv(res,path)
}
getSingleInfo.TQ  <- function(page,myheader){
force(page)
pages  <- paste(page,"&jidu=",1:4,sep="")
ldply(pages,failwith(f=readTable,quiet = T),myheader)
}
readTable  <- function (url,myheader){
force(url)
webpage <- getURL(url,httpheader = myheader,.encoding='utf-8');
pagetree <- htmlTreeParse(webpage,encoding="utf-8", error=function(...){}, useInternalNodes = TRUE,trim=F)
table  <- readHTMLTable(pagetree,header = F)
table  <- table$FundHoldSharesTable[-c(1,2),]
n  <- nrow(table)
table[rev(1:n),]
}
myheader=c("User-Agent"="Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9.1.6) ",
"Accept"="text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
"Accept-Language"="en-us",
"Connection"="keep-alive",
"Accept-Charset"="GB2312,utf-8;q=0.7,*;q=0.7"
)
############使用样例
####直接调用getAllInfo.TQ即可
getAllInfo.TQ(code = "600000",year.start  = 2010,year.end =2014,myheader,"lipufa.csv")
require(RCurl)
require(XML)
require(plyr)
require(TSA)
require(ggplot2)
verifyYears  <- function(code,year.start,year.end,myheader){
url  <-paste("http://vip.stock.finance.sina.com.cn/corp/go.php/vMS_MarketHistory/stockid/",
code,".phtml?year=2014&jidu=1",sep="")
webpage <- getURL(url,httpheader = myheader);
pagetree <- htmlTreeParse(webpage,encoding="utf-8", error=function(...){}, useInternalNodes = TRUE,trim=F)
years <- xpathSApply(pagetree,'//*/form[@name="daily"]/select[@name="year"]/option',xmlValue)
years  <- as.numeric(years)
minYear  <- min(years)
maxYear <- max(years)
if(year.start < minYear || year.end >maxYear){
stop("invalid time interval,max year is\t",maxYear,"min year is\t" ,minYear)
}
}
###主函数
#'@param code  股票代码在沪深交易所网站课直接获得
#'@param year.start 起始年
#'@param 终止年
#'@param path 保存到的文件路径，直接输入文件名则保存在工作目录下
#'@return  不凡任何值，直接将数据写入path中（直接读取会出现错误）
getAllInfo.TQ  <- function(code,year.start,year.end,myheader,path){
verifyYears(code,year.start,year.end,myheader)
years =seq(from = year.start,to = year.end,by = 1);
urls  <- paste("http://vip.stock.finance.sina.com.cn/corp/go.php/vMS_MarketHistory/stockid/",
code,".phtml?year=",years,sep="");
res <- ldply(urls,getSingleInfo.TQ,myheader,.progress =  "win")
names(res) <- c("date","open","high","close","low","volume","total_pay")
write.csv(res,path)
}
getSingleInfo.TQ  <- function(page,myheader){
force(page)
pages  <- paste(page,"&jidu=",1:4,sep="")
ldply(pages,failwith(f=readTable,quiet = T),myheader)
}
readTable  <- function (url,myheader){
force(url)
webpage <- getURL(url,httpheader = myheader,.encoding='utf-8');
pagetree <- htmlTreeParse(webpage,encoding="utf-8", error=function(...){}, useInternalNodes = TRUE,trim=F)
table  <- readHTMLTable(pagetree,header = F)
table  <- table$FundHoldSharesTable[-c(1,2),]
n  <- nrow(table)
table[rev(1:n),]
}
myheader=c("User-Agent"="Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9.1.6) ",
"Accept"="text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
"Accept-Language"="en-us",
"Connection"="keep-alive",
"Accept-Charset"="GB2312,utf-8;q=0.7,*;q=0.7"
)
############使用样例
####直接调用getAllInfo.TQ即可
getAllInfo.TQ(code = "600000",year.start  = 1975,year.end =2014,myheader,"lipufa.csv")
help(xpathSApply)
myheader <- c(
"Host"="vip.stock.finance.sina.com.cn",
"User-Agent"="Mozilla/5.0 (Windows NT 6.1; WOW64; rv:38.0) Gecko/20100101 Firefox/38.0",
"Accept"="text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
"Accept-Language"="zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3",
"Accept-Encoding"="gzip, deflate",
"Connection"="keep-alive",
"Cache-Control"="max-age=0"
)
webpage <- getURL("http://vip.stock.finance.sina.com.cn/corp/go.php/vMS_MarketHistory/stockid/600636.phtml", header=myheader)
webpage
pagetree <- htmlTreeParse(webpage,encoding="utf-8", error=function(...){}, useInternalNodes = TRUE,trim=F)
years <- xpathSApply(pagetree,'//*/form[@name="daily"]/select[@name="year"]/option',xmlValue)
years
library(RCurl)
library(XML)
myheader <- c(
"Host"="vip.stock.finance.sina.com.cn",
"User-Agent"="Mozilla/5.0 (Windows NT 6.1; WOW64; rv:38.0) Gecko/20100101 Firefox/38.0",
"Accept"="text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
"Accept-Language"="zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3",
"Accept-Encoding"="gzip, deflate",
"Connection"="keep-alive",
"Cache-Control"="max-age=0"
)
webpage <- getURL("http://vip.stock.finance.sina.com.cn/corp/go.php/vMS_MarketHistory/stockid/600636.phtml", header=myheader)
pagetree <- htmlTreeParse(webpage,encoding="utf-8", error=function(...){}, useInternalNodes = TRUE,trim=F)
years <- xpathSApply(pagetree,'//*/form[@name="daily"]/select[@name="year"]/option',xmlValue)
years
pagetree
webpage
pagetree
max.Year <- max(years)
min.Year <- min(years)
stockYears <- seq(min.Year,max.Year,by=1)
stockYears <- seq(from=min.Year,to=max.Year,by=1)
max.Year <- max(years)
min.Year <- min(years)
stockYears <- seq(from=min.Year,to=max.Year,by=1)
stockYears <- seq(from = min.Year, to=max.Year, by=1)
min.Year
max.Year
stockYears <- seq(from = as.numeric(min.Year), to=as.numeric(max.Year), by=1)
stockYears
urls  <- paste("http://vip.stock.finance.sina.com.cn/corp/go.php/vMS_MarketHistory/stockid/",
'600636',".phtml?year=",years,sep="");
urls
urls  <- paste("http://vip.stock.finance.sina.com.cn/corp/go.php/vMS_MarketHistory/stockid/",
'600636',".phtml?year=",years,sep="")
urls
for (x in urls) {
print(x)
}
for (url in urls) {
pages  <- paste(url,"&jidu=",1:4,sep="")
for (page in pages) {
print(x)
}
}
for (url in urls) {
pages  <- paste(url,"&jidu=",1:4,sep="")
for (page in pages) {
print(x)
}
}
urls
pages  <- paste(url,"&jidu=",1:4,sep="")
pages
for (url in urls) {
pages  <- paste(url,"&jidu=",1:4,sep="")
for (page in pages) {
print(page)
}
}
for (url in urls) {
pages  <- paste(url,"&jidu=",1:4,sep="")
for (page in pages) {
print(page)
webpage <- getURL(page,httpheader = myheader,.encoding='utf-8');
pagetree <- htmlTreeParse(webpage,encoding="utf-8", error=function(...){}, useInternalNodes = TRUE,trim=F)
table  <- readHTMLTable(pagetree,header = F)
table  <- table$FundHoldSharesTable[-c(1,2),]
n  <- nrow(table)
table[rev(1:n),]
}
}
page
pagetree <- htmlTreeParse(webpage,encoding="utf-8", error=function(...){}, useInternalNodes = TRUE,trim=F)
table  <- readHTMLTable(pagetree,header = F)
table  <- table$FundHoldSharesTable[-c(1,2),]
table
table[rev(1:n),]
webpage <- getURL(page,httpheader = myheader,.encoding='utf-8');
pagetree <- htmlTreeParse(webpage,encoding="utf-8", error=function(...){}, useInternalNodes = TRUE,trim=F)
table  <- readHTMLTable(pagetree,header = F)
table  <- table$FundHoldSharesTable[-c(1,2),]
n  <- nrow(table)
table[rev(1:n),]
for (url in urls) {
pages  <- paste(url,"&jidu=",1:4,sep="")
for (page in pages) {
print(page)
webpage <- getURL(page,httpheader = myheader,.encoding='utf-8');
pagetree <- htmlTreeParse(webpage,encoding="utf-8", error=function(...){}, useInternalNodes = TRUE,trim=F)
table  <- readHTMLTable(pagetree,header = F)
table  <- table$FundHoldSharesTable[-c(1,2),]
n  <- nrow(table)
table[rev(1:n),]
}
}
url
urls
url <- urls[1]
pages  <- paste(url,"&jidu=",1:4,sep="")
pages
webpage <- getURL(page[1],httpheader = myheader,.encoding='utf-8');
page[1]
webpage <- getURL(page[1],httpheader = myheader,.encoding='utf-8');
webpage <- getURL(page[1],httpheader = myheader);
webpage <- getURL(page[1],header = myheader);
webpage <- getURL(page[1],header = myheader);
webpage
pagetree <- htmlTreeParse(webpage,encoding="utf-8", error=function(...){}, useInternalNodes = TRUE,trim=F)
table  <- readHTMLTable(pagetree,header = F)
table  <- table$FundHoldSharesTable[-c(1,2),]
table
n  <- nrow(table)
table[rev(1:n),]
table[rev(1:n),]
table[rev(1:n),]
for (url in urls) {
pages  <- paste(url,"&jidu=",1:4,sep="")
for (page in pages) {
print(page)
webpage <- getURL(page,header = myheader);
pagetree <- htmlTreeParse(webpage,encoding="utf-8", error=function(...){}, useInternalNodes = TRUE,trim=F)
table  <- readHTMLTable(pagetree,header = F)
table  <- table$FundHoldSharesTable[-c(1,2),]
n  <- nrow(table)
result <- rbin(result,table[rev(1:n),])
}
}
for (url in urls) {
pages  <- paste(url,"&jidu=",1:4,sep="")
for (page in pages) {
print(page)
webpage <- getURL(page,header = myheader);
pagetree <- htmlTreeParse(webpage,encoding="utf-8", error=function(...){}, useInternalNodes = TRUE,trim=F)
table  <- readHTMLTable(pagetree,header = F)
table  <- table$FundHoldSharesTable[-c(1,2),]
n  <- nrow(table)
result <- rbind(result,table[rev(1:n),])
}
}
result <- data.frame()
for (url in urls) {
pages  <- paste(url,"&jidu=",1:4,sep="")
for (page in pages) {
print(page)
webpage <- getURL(page,header = myheader);
pagetree <- htmlTreeParse(webpage,encoding="utf-8", error=function(...){}, useInternalNodes = TRUE,trim=F)
table  <- readHTMLTable(pagetree,header = F)
table  <- table$FundHoldSharesTable[-c(1,2),]
n  <- nrow(table)
temp <-table[rev(1:n),]
result <- rbind(result,temp)
}
}
result
urls  <- paste("http://vip.stock.finance.sina.com.cn/corp/go.php/vMS_MarketHistory/stockid/",
'600636',".phtml?year=",years,sep="")
result <- data.frame()
for (url in urls) {
pages  <- paste(url,"&jidu=",1:4,sep="")
for (page in pages) {
print(page)
webpage <- getURL(page,header = myheader);
pagetree <- htmlTreeParse(webpage,encoding="utf-8", error=function(...){}, useInternalNodes = TRUE,trim=F)
table  <- readHTMLTable(pagetree,header = F)
table  <- table$FundHoldSharesTable[-c(1,2),]
n  <- nrow(table)
temp <-table[rev(1:n),]
result <- rbind(result,temp)
}
}
result
nrow(result)
urls
urls
result <- data.frame()
for (url in urls) {
pages  <- paste(url,"&jidu=",1:4,sep="")
for (page in pages) {
webpage <- getURL(page,header = myheader);
pagetree <- htmlTreeParse(webpage,encoding="utf-8", error=function(...){}, useInternalNodes = TRUE,trim=F)
table  <- readHTMLTable(pagetree,header = F)
table  <- table$FundHoldSharesTable[-c(1,2),]
n  <- nrow(table)
temp <-table[rev(1:n),]
result <- rbind(result,temp)
}
}
result <- data.frame()
for (url in urls) {
pages  <- paste(url,"&jidu=",1:4,sep="")
for (page in pages) {
if (url.exists(page)){
webpage <- getURL(page,header = myheader);
pagetree <- htmlTreeParse(webpage,encoding="utf-8", error=function(...){}, useInternalNodes = TRUE,trim=F)
table  <- readHTMLTable(pagetree,header = F)
table  <- table$FundHoldSharesTable[-c(1,2),]
n  <- nrow(table)
temp <-table[rev(1:n),]
result <- rbind(result,temp)
}
}
}
